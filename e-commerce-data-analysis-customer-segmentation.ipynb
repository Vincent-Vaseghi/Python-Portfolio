{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n* [Introduction](#introduction)\n    - [About the Project](#project)\n    - [About the Data](#data)\n* [Getting Started](#getting-started)\n    - [Import Python Libraries](#import-libraries)\n    - [Import Data](#import-data)\n* [Exploratory Data Analysis (EDA)](#eda)\n    - [EDA Technical Insights](#eda-tec)\n    - [EDA Managerial Insights](#eda-man)\n* [RFM Analysis](#rfm)\n    - [RFM Technical Insights](#rfm-tec)\n    - [RFM Managerial Insights](#rfm-man)\n* [Resources & References](#reference)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"introduction\"></a>\n# Introduction\n### About the Project\nE-Commerce Data Analysis & Customer Segmentation (EDA & RFM)\n\nIn this **Jupyter notebook**, we're going to use **Python** and perform some **exploratory data analysis (EDA)** along with some machine learning techniques. I've tried to make the notebook beginner friendly, so if you are new to the whole world of data analysis, data science and machine learning, you can enjoy it too.\n\n### About the Data\nI've used a [Kaggle dataset](https://www.kaggle.com/datasets/carrie1/ecommerce-data?datasetId=1985) for this notebook. Originially, the dataset is provided by the The [UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/ml/datasets/online+retail) and contains actual e-commerce transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based online retailer. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n**What do the instances (aka columns/variables/features) that comprise the dataset represent?**\n\n- **InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. \n- **StockCode:** Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n- **Description:** Product (item) name. Nominal.\n- **Quantity:** The quantities of each product (item) per transaction. Numeric.\t\n- **InvoiceDate:** Invice Date and time. Numeric, the day and time when each transaction was generated.\n- **UnitPrice:** Unit price. Numeric, Product price per unit in sterling.\n- **CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n- **Country:** Country name. Nominal, the name of the country where each customer resides. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"getting-started\"></a>\n# Getting Started\n<a id=\"import-libraries\"></a>\n### Import Python Libraries\nHere are the python libraries I'd like to import:\n- **NumPy** for linear algebra\n- **Pandas** for tabular data manipulation & processing, CSV file I/O\n- **DataPrep** for exploratory data analysis and data cleaning (built on top of Pandas, Matplotlib, Jupyter Widgets, Bokeh, Flask, Dask, etc.)\n- **Matplotlib** for data visualization (scatterplots, bar charts, histograms, etc.)\n- **Seaborn** for data visualization and statistical plotting (built on top of Matplotlib)\n- **Plotly** for interactive data visualization\n- **Scikit-learn** for data modeling and machine learning","metadata":{}},{"cell_type":"code","source":"!pip install dataprep\n!pip install -qq plotly_express","metadata":{"_kg_hide-output":true,"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-07T02:37:19.782651Z","iopub.execute_input":"2022-08-07T02:37:19.783047Z","iopub.status.idle":"2022-08-07T02:38:15.818836Z","shell.execute_reply.started":"2022-08-07T02:37:19.783002Z","shell.execute_reply":"2022-08-07T02:38:15.817598Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom dataprep.eda import plot, plot_missing, plot_correlation, create_report\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-08-07T02:39:18.150485Z","iopub.execute_input":"2022-08-07T02:39:18.150955Z","iopub.status.idle":"2022-08-07T02:39:21.899191Z","shell.execute_reply.started":"2022-08-07T02:39:18.150918Z","shell.execute_reply":"2022-08-07T02:39:21.898198Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"import-data\"></a>\n### Import Data\nAs mentioned in the introduction, data is pooled from a Kaggle e-commerce dataset. You can learn more on how to use Kaggle Datasets <a href=\"https://www.kaggle.com/docs/notebooks#datasets\">here</a>.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/ecommerce-data/data.csv\", encoding = 'ISO-8859-1')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T02:39:28.829494Z","iopub.execute_input":"2022-08-07T02:39:28.829896Z","iopub.status.idle":"2022-08-07T02:39:29.862801Z","shell.execute_reply.started":"2022-08-07T02:39:28.829864Z","shell.execute_reply":"2022-08-07T02:39:29.861608Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"eda\"></a>\n# Exploratory Data Analysis (EDA)\n\nLet's explore:\n- Column names and their associated data types\n- Total number of columns & rows\n- Duplicate values\n- Missing (null) values\n- Negative values\n- Data consistency\n- Basic statistics for quantitative variables (Count, Mean, Min, Median, Max)\n","metadata":{}},{"cell_type":"code","source":"# Changing the invoice dates data type to datetime format\ndf['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])","metadata":{"execution":{"iopub.status.busy":"2022-08-07T02:39:33.024103Z","iopub.execute_input":"2022-08-07T02:39:33.024511Z","iopub.status.idle":"2022-08-07T02:39:35.471816Z","shell.execute_reply.started":"2022-08-07T02:39:33.024478Z","shell.execute_reply":"2022-08-07T02:39:35.470611Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plot(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"eda-tec\"></a>\n## EDA Technical Insights\n\n**Columns & Rows**\n- As expected, there are 8 Columns (features/variables).\n- There are 541909 Rows.\n \n**Duplicate Values**\n- There are 5268 (1%) duplicate rows.\n    - **Must be removed before further analysis.**\n\n**Missing Values**\n- There are 136534 (3.1%) missing cells.\n- Only 2 columns have missing values: **CustomerID** (135080 or 24.93%) and **Description** (1454 or 0.27%)\n    - **Missing \"CustomerID\" Must be excluded before further analysis.**\n\n**Negative Values**\n- **Quantity** has 10624 (1.96%) negative values\n    - Some of these are associated with **cancelled orders**. Must be indentified and removed before further analysis.\n    - Anything beyond cancelled orders **must be excluded before further analysis.**\n\n**Skew** \n- Both **Quantity** and **UnitPrice** are skewed to the right (towards higher amounts).\n\n**High Cardinality** \n- **InvoiceNo** has a high cardinality: 25900 distinct values\n- **StockCode** has a high cardinality: 4070 distinct values\n- **Description** has a high cardinality: 4223 distinct values\n- **InvoiceDate** has a high cardinality: 23260 distinct values\n","metadata":{}},{"cell_type":"code","source":"# change columns type - String to Int type \n#df['CustomerID'] = df['CustomerID'].astype('int64')\n\n# Excluding missing values\ndf.dropna(subset = ['CustomerID'], axis = 0, inplace = True)\ndf = df[df.isin([\"NaN\",\"missing\",\"?\",\"??\"]).any(axis=1) == False]\n\n# Excluding Duplicates\ndf = df.drop_duplicates()\n\n# Canceled Orders can be further explored\n# df_cancelled = df[df['InvoiceNo'].str.contains('C', regex=True)]['InvoiceNo'].unique()\n\n# Ensuring \"UnitPrice\" & \"Quantity\" only have positive values\ndf = df[(df[\"UnitPrice\"] > 0) & (df[\"Quantity\"] > 0)]\n\n# Ensuring Data Consistency for the \"Description\" and excluding irrelevant values\ndf[\"Description\"] = df[\"Description\"].str.lower().str.strip()\ndf = df[df[\"Description\"].isin([\"amazon fee\", \"samples\", \"postage\", \"packing charge\",\"manual\",\"discount\",\"adjust bad debt\",\"bank charges\",\"cruk commission\",\"next day carriage\"]) == False]\n\n# Optional: Country names can be cleaned if it's confusing to the audience\n# e.g.: RSA = South Africa / EIRE = Ireland\n# df.drop([\"Unspecified\",\"European Community\"], axis = 0, inplace = True)\n\n# Total Purcahse is an important quantittive variable (TotalPurchase = Price * Quantity)\ndf['TotalPurchase'] = df['Quantity'] * df['UnitPrice']","metadata":{"execution":{"iopub.status.busy":"2022-08-07T02:39:40.092859Z","iopub.execute_input":"2022-08-07T02:39:40.093267Z","iopub.status.idle":"2022-08-07T02:39:43.235200Z","shell.execute_reply.started":"2022-08-07T02:39:40.093235Z","shell.execute_reply":"2022-08-07T02:39:43.234074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Total Purchase by each Country can be further explored\n#df = df.groupby(\"Country\").agg({'TotalPurchase': lambda x: x.sum()})\n\n# Observing the Order Size per Invoice\ndf_orders = df.groupby(by=['CustomerID', 'InvoiceNo', 'TotalPurchase'], as_index=False)['Description'].count().sort_values(by=['Description'], ascending = False)\ndf_orders = df_orders.rename(columns = {'Description':'OrderSize'})\ndf_orders.sort_values(by=['OrderSize'], ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T02:41:08.804640Z","iopub.execute_input":"2022-08-07T02:41:08.805062Z","iopub.status.idle":"2022-08-07T02:41:08.823766Z","shell.execute_reply.started":"2022-08-07T02:41:08.805026Z","shell.execute_reply":"2022-08-07T02:41:08.822516Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"eda-man\"></a>\n## EDA Managerial Insights","metadata":{}},{"cell_type":"code","source":"plot(df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total Purchase by each Country can be further explored\n#df = df.groupby(\"Country\").agg({'TotalPurchase': lambda x: x.sum()})\n\n# Observing the Order Size per Invoice\ndf_orders = df.groupby(by=['CustomerID', 'InvoiceNo', 'TotalPurchase'], as_index=False)['Description'].count().sort_values(by=['Description'], ascending = False)\ndf_orders = df_orders.rename(columns = {'Description':'OrderSize'})\ndf_orders.sort_values(by=['OrderSize'], ascending = False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Above figures showcase:**\n    - Majority of purcahses (89.17%) made from the the UK. \n    - Total purchase figures made by different countries\n    - Germany, France, Ireland (EIRE), Spain, Netherlands follow UK in terms of the number of purchases.\n    - Top 10 StockIDs\n    - Top 10 products\n    - Busiest month of the year (November)\n\n\n- **Note to DE (Data Engineer)/DBA (Database Administrator)/ Upstream**\n    - \"StockCode\" and \"Description\": Each \"StockCode\" must have a unique \"Description\". Any further comments must be documented under a sepaate column (e.g. \"Comments\").\n    - Cancelled Orders should have a separate note on a dedicated column (e.g. \"Comments\") besides adding a C to the \"InvoiceID\" or messing with the \"Description\"","metadata":{}},{"cell_type":"markdown","source":"<a id=\"rfm\"></a>\n# RFM Analysis\n\nRFM (Recency, Frequency, Monetary) analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups. RFM helps divide customers into various categories or clusters to identify customers who are more likely to respond to promotions and also for future personalization services.\n\n- Recency (R): How recently purchase was made.\n- Frequency (F): How frequently purchase is made.\n- Monetary Value (M): How much is spent.\n\n\n**Business Implications**\n\nBased on the assigned RFM score, customers are divided into 11 segments:\n\n- **Champion:** Bought recently, order often and spend the most.\n- **Loyal:** Orders regularly. Responsive to promotions.\n- **Potential Loyalist:** Recent customers, and spent a good amount.\n- **New Customers:** Bought most recently.\n- **Promising:** Potential loyalist a few months ago. Spends frequently and a good amount. But the last purchase was several weeks ago.\n- **Core:** Standard customers with not too long-ago purchase.\n- **Needs attention:** Core customers whose last purchase happened more than one month ago.\n- **Can’t lose them but losing:** Made the largest orders, and often. But haven’t returned for a long time.\n- **At Risk:** Similar to “Can’t lose them but losing” but with smaller monetary and frequency value.\n- **Losing but engaged:** Made their last purchase a long time ago but in the last 4 weeks either visited the site or opened an email.\n- **Lost:** Made last purchase long time ago and didn’t engage at all in the last 4 weeks.","metadata":{}},{"cell_type":"code","source":"reference_date = dt.datetime(2011, 12, 12)\n\nrfm = df.groupby('CustomerID').agg({'InvoiceDate': lambda InvoiceDate: (reference_date - InvoiceDate.max()).days,\n                                     'InvoiceNo': lambda InvoiceNo: InvoiceNo.nunique(),\n                                     'TotalPurchase': lambda TotalPurchase: TotalPurchase.sum()})\n\nrfm.columns = ['recency', 'frequency', 'monetary']\n\n# Setting Recency Score: most recent/latest purchase is assigned 5 (high value)\nrfm[\"RecencyScore\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n\n# Setting Frequency Score: most frequent is assigned 5 (high value)\nrfm[\"FrequencyScore\"] = pd.qcut(rfm['frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n\n# Setting Monetary Score: highest monetary purchase is assigned 5 (high value)\nrfm[\"MonetaryScore\"] = pd.qcut(rfm['monetary'], 5, labels=[1, 2, 3, 4, 5])\n\n#we'll not include monetory_score.\nrfm[\"RFM_Score\"] = (rfm['RecencyScore'].astype(str) + rfm['FrequencyScore'].astype(str) + rfm['MonetaryScore'].astype(str))\n\nseg_map = {\n    r'[4-5][4-5][4-5]': 'champion',\n    r'[3-5][3-5][1-3]': 'loyal',\n    r'[4-5][1-3][3-5]': 'potential_loyalist',\n    r'[4-5][1-2][1-5]': 'new_customers',\n    r'[2-3][1-3][3-5]': 'promising',\n    r'[2-3][2-3][2-3]': 'core',\n    r'[1-2][2-3][1-3]': 'need_attention',\n    r'[1-3][3-5][4-5]': 'cant_lose',\n    r'[1-2][2-5][1-3]': 'at_Risk',\n    r'[2-3][1-2][1-5]': 'losing_Engaged',\n    r'1[1-2][1-5]': 'lost'\n}\nrfm['segment'] = rfm['RFM_Score'].replace(seg_map, regex=True)\nrfm.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"rfm-tec\"></a>\n## RFM Technical Insights\n\nEach of the RFM components is assigned a score between 1 and 5 (5 being the best score). \n\n**The Recency (R), Frequency (F), Monetary (M) Breakdown:**\n- Champion [R(4 – 5), F(4 – 5), M(4 - 5)]\n- Loyal  [R(3 – 5), F(3 – 5), M(1 - 3)]\n- Potential Loyalist [R(4 – 5), F(1 – 3), M(3 - 5)]\n- New Customers R [(4 – 5), F(1 – 2), M(1 - 5)]\n- Promising [R(2 – 3), F(1 – 3), M (3 - 5)]\n- Core [R(2-3), F(2-3), M(2-3)]\n- Need Attention R [(1 – 2), F(2 – 3), M(1 - 3)]\n- Can’t Lose but Losing [R(1 – 3), F(3 – 5), M(4 - 5)]\n- At Risk [R(1 – 2), F(2 – 5), M(1 - 3)]\n- Losing but Engaged [R(2 – 3), F(1 - 2), M(1 - 5)]\n- Lost [R(1), F(1 – 2), M(1 - 5)]","metadata":{}},{"cell_type":"code","source":"segments_count = rfm.groupby(\"segment\").agg({\"CustomerID\": \"count\"})\nsegments_count.reset_index(inplace=True)\nsegments_count.columns = ['segment', 'count']\nsegments_count.sort_values(by=[\"count\"], ascending = False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"rfm-man\"></a>\n## RFM Managerial Insights","metadata":{}},{"cell_type":"code","source":"px.treemap(segments_count, path=[px.Constant(\"segment\"),'segment'], values='count',\n                 color='count', hover_data=['count'], \n                 color_continuous_scale='RdBu',\n                 color_continuous_midpoint=np.average(segments_count['count'], weights=segments_count['count']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**How to treat each RFM segment**\n\n- **Champion:** Reward them. Can be early adopters of new products. Will promote your brand. Most likely to send referrals.\n- **Loyal:** Upsell higher value products. Ask for reviews.\n- **Potential Loyalist:** Offer membership / loyalty program. Keep them engaged. Offer personalised recommendations.\n- **New Customers:** Provide on-boarding support, give them early access, start building relationship.\n- **Promising:** Offer coupons. Bring them back to the platform and keep them engaged. Offer personalised recommendations.\n- **Core:** Make limited time offers.\n- **Needs attention:** Make limited time offers. Offer personalised recommendations.\n- **Can’t lose them but losing:** Win them back via renewals or newer products, don’t lose them to competition. Talk to them if necessary. Spend time on highest possible personalisation.\n- **At Risk:** Provide helpful resources on the site. Send personalised emails.\n- **Losing but engaged:** Make subject lines of emails very personalised. Revive their interest by a specific discount on a specific product.\n- **Lost:** Revive interest with reach out campaign. Ignore otherwise.\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"reference\"></a>\n# Resources & References\n\n**Python Libraries' User Guides & Tutorials**\n- <a href=\"https://numpy.org/doc/stable/\">Numpy Getting Started and User Guide</a>\n- <a href=\"https://pandas.pydata.org/docs/\">Pandas Getting Started and User Guide</a>\n- <a href=\"https://matplotlib.org/stable/users/index.html\">Matplotlib User Guide</a>\n- <a href =\"https://seaborn.pydata.org/tutorial.html\">Seaborn: Statistical Data Visualization. User Guide and Tutorial</a> \n- <a href=\"https://plotly.com/python/getting-started/\">Plotly Getting Started in Python</a>\n- <a href=\"https://docs.dataprep.ai/user_guide/user_guide.html\">DataPrep User Guide</a>\n- <a href =\"https://scikit-learn.org/stable/user_guide.html\">Scikit-learn: Machine Learning in Python. User Guide</a>\n- <a href=\"https://docs.scipy.org/doc/scipy/\">SciPy Getting Started and User Guide</a>\n\n\n**Kaggle Courses**\n- <a href =\"https://www.kaggle.com/learn/python\">Kaggle Courses: Python</a> (beginner friendly)\n- <a href =\"https://www.kaggle.com/learn/pandas\">Kaggle Courses: Pandas</a> (beginner friendly)\n- <a href =\"https://www.kaggle.com/learn/data-cleaning\">Kaggle Courses: Data Cleaning</a> (beginner friendly)\n- <a href =\"https://www.kaggle.com/learn/data-visualization\">Kaggle Courses: Data Visualization</a> (beginner friendly)\n- <a href =\"https://www.kaggle.com/learn/intro-to-machine-learning\">Kaggle Courses: Intro to Machine Learning</a> (beginner friendly)\n- <a href =\"https://www.kaggle.com/learn/intermediate-machine-learning\">Kaggle Courses: Intermediate Machine Learning</a>\n- <a href =\"https://www.kaggle.com/learn/feature-engineering\">Kaggle Courses: Feature Engineering</a>\n- <a href =\"https://www.kaggle.com/learn/machine-learning-explainability\">Kaggle Courses: Machine Learning Explainability</a>\n\n**Inspiring Kaggle Notebooks**\n- <a href =\"https://www.kaggle.com/code/fabiendaniel/customer-segmentation/notebook\">Customer-segmentation</a> by Fabien Daniel\n- <a href=\"https://www.kaggle.com/code/anmoltripathi/complete-e-commerce-analysis\">Complete E-Commerce Analysis</a> by Anmol Tripathi\n- <a href=\"https://www.kaggle.com/code/allunia/e-commerce-sales-forecast/notebook\">E-Commerce Sales Forecast</a> by Laura Fink\n- <a href =\"https://www.kaggle.com/code/sercanyesiloz/crm-analytics/notebook\">CRM Analytics</a> by Sercan Yeşilöz\n\n**Others**\n- Segal, Troy (August 23, 2021). Investopedia.com, <a href =\"https://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp\">Recency, Frequency, Monetary Value (RFM)</a>","metadata":{}}]}